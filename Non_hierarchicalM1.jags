model {

  # --- Priors ---
  alpha ~ dbeta(2, 2)
  b0 ~ dnorm(0, 0.01)
  b1 ~ dnorm(0, 0.01)

  # --- Subject loop ---
  for (s in 1:NS) {
  
    # Initialize Q-values at t = 1
    for (stim in 1:NStim) {
      for (a in 1:NC) {
        Q[s, stim, a, 1] <- 0.5
      }
    }
    
    # --- Trial loop ---
    for (t in 2:NT[s]) {
    
      # Compute prediction error (between recived reward and expected = q value)
      delta[s, t] <- rew[s, t - 1] - Q[s, stim_id[s, t - 1], choice[s, t - 1], t - 1]

      for (stim in 1:NStim) {
        for (a in 1:NC) {
          Q[s, stim, a, t] <- ifelse(
            equals(stim, stim_id[s, t - 1]) == 1 && a == choice[s, t - 1],
            Q[s, stim, a, t - 1] + alpha * delta[s, t],
            Q[s, stim, a, t - 1]
          )
        }
      }
      
      # Expected value differences (between the 2 choices)
      V[s, t] <- Q[s, stim_id[s, t], 1, t] - Q[s, stim_id[s, t], 2, t]
      
      # Logistic prediction
      logit(p[s, t]) <- b0 + b1 * V[s, t]
      
      # Observed binary choice
      choice_two[s, t] ~ dbern(p[s, t])
      
      # --- Posterior Predictive Check: to simulate from model ---
      choice_pred[s, t] ~ dbern(p[s, t]) 
    }
  }
}
